{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# BT01: Thu thập dữ liệu\n",
    "(Cập nhật 01/11/2020)\n",
    "\n",
    "Họ tên: ...\n",
    "\n",
    "MSSV: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Cách làm bài và nộp bài\n",
    "&#9889; Bạn lưu ý là mình sẽ dùng chương trình hỗ trợ chấm bài nên bạn cần phải tuân thủ chính xác qui định mà mình đặt ra, nếu không rõ thì hỏi, chứ không nên tự tiện làm theo ý của cá nhân.\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này. Đầu tiên, bạn điền họ tên và MSSV vào phần đầu file ở bên trên. Trong file, bạn làm bài ở những chỗ có ghi là:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "hoặc đối với những phần code không bắt buộc thì là:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "hoặc đối với markdown cell thì là:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "Tất nhiên, khi làm thì bạn xóa dòng `raise NotImplementedError()` đi.\n",
    "Đối những phần yêu cầu code thì thường ở ngay phía dưới sẽ có một (hoặc một số) cell chứa các bộ test để giúp bạn biết đã code đúng hay chưa; nếu chạy cell này không có lỗi gì thì có nghĩa là qua được các bộ test. Trong một số trường hợp, các bộ test có thể sẽ không đầy đủ; nghĩa là, nếu không qua được test thì là code sai, nhưng nếu qua được test thì chưa chắc đã đúng.\n",
    "\n",
    "Trong khi làm bài, bạn có thể cho in ra màn hình, tạo thêm các cell để test. Nhưng khi nộp bài thì bạn xóa các cell mà bạn tự tạo, xóa hoặc comment các câu lệnh in ra màn hình. Bạn lưu ý <font color=red>không được tự tiện xóa các cell hay sửa code của Thầy</font> (trừ những chỗ được phép sửa như đã nói ở trên).\n",
    "\n",
    "Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "\n",
    "*Nên nhớ mục tiêu chính ở đây là <font color=green>học, học một cách chân thật</font>. Bạn có thể thảo luận ý tưởng với bạn khác, nhưng <font color=green>code và bài làm phải là của bạn, dựa trên sự hiểu thật sự của bạn</font>. <font color=red>Nếu vi phạm thì sẽ bị 0 điểm cho toàn bộ môn học.</font>*\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Kernel` - `Restart & Run All`, để restart và chạy tất cả các cell trong notebook của bạn; do đó, trước khi nộp bài, bạn nên chạy thử `Kernel` - `Restart & Run All` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, bạn tạo thư mục nộp bài theo cấu trúc sau:\n",
    "- Thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`)\n",
    "    - File `BT01-ThuThapDuLieu.ipynb` (không cần nộp các file khác)\n",
    "\n",
    "Cuối cùng, bạn nén thư mục `MSSV` này lại và nộp ở link trên moodle. <font color=red>Bạn lưu ý tuân thủ chính xác cấu trúc này.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time # Dùng để sleep chương trình\n",
    "import pandas as pd # Dùng để đọc và hiển thị file csv (Pandas sẽ được học chi tiết ở buổi tới)\n",
    "import datetime as dt # Dùng để xử lý dữ liệu thời gian\n",
    "import re\n",
    "# YOUR CODE HERE (OPTION) \n",
    "# Nếu cần các thư viện khác thì bạn có thể import ở đây"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# ---\n",
    "## 1. Thu thập dữ liệu từ web bằng cách parse HTML (5đ)\n",
    "[Coursera](https://coursera.org) là trang cung cấp các khóa học online, là một nguồn tài liệu hữu ích để học tập. Trong phần này, bạn sẽ thu thập dữ liệu về các khóa học Data Science ở Coursera. \n",
    "\n",
    "Cụ thể là bạn sẽ viết hàm `collect_courses` ở bên dưới. Hàm này có các input như sau:\n",
    "- `course_urls_file`: là chuỗi, cho biết tên của file txt chứa các đường link đến các khóa học của Coursera (tất cả các khóa học, chứ không phải chỉ các khóa học về Data Science), mỗi đường link nằm trên một dòng; bạn sẽ đi theo đường link để lấy thông tin của khóa học. File này đã được cung cấp cho bạn: file \"course_urls.txt\" (mình tạo ra file này bằng cách parse [trang XML này](https://www.coursera.org/sitemap~www~courses.xml)). Theo file [robots.txt](https://www.coursera.org/robots.txt) thì các link trong file này đều được phép thu thập (bạn kiểm tra lại xem có đúng không). \n",
    "- `key_words`: là list, cho biết các từ khóa để lọc ra các link cần lấy. Ví dụ: `key_words=['data-science', 'datascience']` sẽ chỉ thu thập thông tin từ các link mà có từ \"data-science\" HOẶC \"datascience\" (có ở tên đường link, chẳng hạn: https://www.coursera.org/learn/spatial-data-science).\n",
    "- `sleep_time`: là số thực, cho biết sau mỗi lần gửi request và parse lấy dữ liệu thì sẽ sleep bao nhiêu giây trước khi gửi tiếp lần request kế (sleep như vậy để tránh gửi quá nhiều request lên Coursera trong một thời gian ngắn). Trong hàm `collect_courses` bên dưới mình để giá trị mặc định là 1 giây. Trong Python, bạn sleep chương trình bằng câu lệnh `time.sleep(số giây)`.\n",
    "- `courses_file`: là chuỗi, cho biết tên của file csv dùng để lưu dữ liệu thu thập được; đây là file output (file này không có sẵn mà sẽ được tạo ra sau khi chạy hàm của bạn). Mình có cung cấp file output đúng \"correct_courses.csv\" (khi gọi hàm `collect_courses` với `key_words=['data-science', 'datascience']`) để bạn hình dung được nội dung cần có của file output. File này có các phần tử trên mỗi dòng được phân tách nhau bởi tab (`\\t`), và file này mã hóa utf-8. File này gồm có các cột:\n",
    "    - `url`: đường link đến khóa học.\n",
    "    - `title`: tựa đề của khóa học.\n",
    "    - `provider`: trường cung cấp khóa học.\n",
    "    - `rating`: điểm số của khóa học (tại thời điểm bạn thu thập dữ liệu thì giá trị của cột này có thể sẽ hơi khác so với file output đúng của mình, trong trường hợp chưa có ai rate khóa học thì bạn có thể cho `rating` bằng `None`).\n",
    "    - `num_ratings`: số lượng người đã cho điểm cho khóa học (tại thời điểm bạn thu thập dữ liệu thì giá trị của cột này có thể sẽ hơi khác so với file output đúng của mình, trong trường hợp chưa có ai rate khóa học thì bạn có thể cho `num_rating` bằng `None`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem 5 dòng đầu của file \"correct_courses.csv\"\n",
    "df = pd.read_csv('correct_courses.csv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "925ed984709d1910bc53a87d128584ef",
     "grade": false,
     "grade_id": "cell-dc3850a3d53d80be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def collect_courses(course_urls_file, key_words, courses_file, sleep_time=1):\n",
    "    # YOUR CODE HERE\n",
    "    courses_link = []\n",
    "    f = open(course_urls_file,\"r\")\n",
    "    for link in f:\n",
    "        for key_word in key_words:\n",
    "            if(key_word in link):\n",
    "                courses_link.append(link.rstrip('\\n'))\n",
    "    df = pd.DataFrame(columns=['url','title','provider','rating','num_ratings'])\n",
    "    for link in courses_link:\n",
    "        try:\n",
    "            kt = True\n",
    "            while(kt):\n",
    "                html_text = requests.get(link).text\n",
    "                tree = BeautifulSoup(html_text, 'html.parser')\n",
    "                if(tree.find('h1',{'class':'banner-title m-b-0 banner-title-without--subtitle'})!= None):\n",
    "                    title = tree.find('h1',{'class':'banner-title m-b-0 banner-title-without--subtitle'}).string\n",
    "                else:\n",
    "                    continue\n",
    "                if(tree.find('h4',{'class':'headline-4-text bold rc-Partner__title'}).string!= None):\n",
    "                    provider = tree.find('h4',{'class':'headline-4-text bold rc-Partner__title'}).string\n",
    "                else:\n",
    "                    continue\n",
    "                if(tree.find('span',{'class':'_16ni8zai m-b-0 rating-text number-rating number-rating-expertise'}) != None):\n",
    "                    rating = re.findall(r'[-+]?([0-9]*\\.[0-9]+|[0-9]+)',tree.find('span',{'class':'_16ni8zai m-b-0 rating-text number-rating number-rating-expertise'}).text)[0]\n",
    "                else:\n",
    "                    continue\n",
    "                if(tree.find('div',{'class':'_wmgtrl9 color-white ratings-count-expertise-style'})):\n",
    "                    num_ratings = re.split(\"\\s\",tree.find('div',{'class':'_wmgtrl9 color-white ratings-count-expertise-style'}).text)[0]\n",
    "                else:\n",
    "                    continue\n",
    "                kt = False\n",
    "            temp = [link,title,provider,rating,num_ratings]\n",
    "            a_series = pd.Series(temp, index = df.columns)\n",
    "            df = df.append(a_series, ignore_index=True)\n",
    "            time.sleep(sleep_time)\n",
    "        except Exception as e: # Có thể là do hết lượng request được phép, hoặc hết page, ...\n",
    "            print(f'Error: {e}')\n",
    "    df.to_csv(courses_file,sep='\\t',index = False)\n",
    "    return df\n",
    "    raise NotImplementedError()\n",
    "collect_courses('course_urls.txt', ['data-science', 'datascience'], 'courses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79c8d10163f79d7d22e94f68571f8c63",
     "grade": true,
     "grade_id": "cell-f7ba8a08f45c6cf9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "collect_courses('course_urls.txt', ['data-science', 'datascience'], 'courses.csv')\n",
    "courses = pd.read_csv('courses.csv', sep='\\t')\n",
    "assert courses.shape == (24, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62a3bb1c02fe708c3dff8e41460d4c78",
     "grade": false,
     "grade_id": "cell-69bae8100b51ecac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "---\n",
    "## 2. Thu thập dữ liệu từ web bằng cách dùng web API (5đ)\n",
    "Trong phần này, bạn sẽ dùng GitHub API để thu thập các thùng chứa về Data Science. Để đơn giản, bạn sẽ dùng API không chứng thực (không cần đăng ký tài khoản, không cần key) của GitHub. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 2.1. Thu thập ít hơn hoặc bằng 1000 thùng chứa (2.5đ)\n",
    "Đầu tiên, bạn sẽ viết hàm `collect_repositories` ở bên dưới. Hàm này có các input:\n",
    "- `start_date` và `end_date`: là chuỗi, cho biết là muốn tìm các thùng chứa được tạo từ ngày nào đến ngày nào (bao gồm cả 2 đầu). Ví dụ, `start_date='2017-01-01'` (năm-tháng-ngày) và `end_date='2017-01-31'`.\n",
    "- `keyword`: là chuỗi, cho biết là muốn tìm kiếm các thùng chứa với từ khóa nào (xuất hiện ở tên thùng chứa hoặc phần mô tả của thùng chứa). Ví dụ, `keyword='data science'`.\n",
    "- `per_page`: là số nguyên, cho biết là muốn bao nhiêu kết quả trên một page. Hiện giờ GitHub cho tối đa là `per_page=100`.\n",
    "\n",
    "Trong hàm này bạn sẽ vào đường link `f'https://api.github.com/search/repositories?q={keyword} created:{start_date}..{end_date}&per_page={per_page}'` (dạng f-string trong Python) để thu thập dữ liệu. Ví dụ, bạn có thể vào thử ở web browser: https://api.github.com/search/repositories?q=data%20science%20created:2017-01-01..2017-01-31&per_page=100 (khi nhập một đường link vào web browser và enter thì một số ký tự sẽ bị mã hóa; ví dụ khoảng trắng sẽ bị mã hóa là %20 hoặc +), hoặc dùng thư viện Requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Thư viện requests sẽ tự động mã hóa khoảng trắng cho bạn\n",
    "# Bạn có thể xem đường link sau khi đã mã hóa bằng câu lệnh: r.url\n",
    "r = requests.get('https://api.github.com/search/repositories?q=data science created:2017-01-01..2017-01-31&per_page=100')\n",
    "#r = requests.get('https://api.github.com/search/repositories?q=data+science+created%3A2017-01-01..2017-01-15&per_page=100&page=7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Xem 100 ký tự đầu tiên trong chuỗi JSON lấy được\n",
    "print(r.text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Bạn thấy \"total_count\" có giá trị là 1570, nghĩa là tìm được 1570 thùng chứa (tại thời điểm bạn chạy thì có thể khác một ít, vì có thể xảy ra trường hợp chủ thùng chứa xóa thùng chứa đi, hoặc chuyển sang private). Tuy nhiên, đây chỉ là trang đầu tiên và chỉ có 100 thùng chứa (số lượng phần tử của \"items\"). Link tới trang kế tiếp nằm trong headers của nội dung gửi về từ server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "r.headers['Link']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Link tới trang kế tiếp là link mà ở bên cạnh phía phải có từ `rel=\"next\"`. `rel=\"last\"` nghĩa là trang cuối. Vì đây là trang đầu tiên nên chỉ có \"next\" và \"last\", trang ở giữa còn có thêm \"first\" (trang đầu) và \"prev\" (trang trước). Bạn có thể xem thêm ở [document](https://docs.github.com/en/free-pro-team@latest/rest/guides/traversing-with-pagination).\n",
    "\n",
    "Nếu để ý thì bạn thấy trang cuối là `page=10`, nghĩa là tất cả các trang chỉ có $10\\times100=1000$ thùng chứa. Trong khi đó, \"total_count\" là 1570. Lý do: \"the GitHub Search API provides up to **1,000 results for each search**\" ([document](https://docs.github.com/en/free-pro-team@latest/rest/reference/search)). Trong hàm này chỉ yêu cầu bạn lấy hết kết quả ở tất cả các trang là được ($\\le1000$ kết quả). Việc lấy $>1000$ kết quả sẽ làm ở phần kế tiếp.\n",
    "\n",
    "Một yêu cầu nữa trong hàm này là: khi request không được (`r.ok` có giá trị là `False`) do hết số lượng request được phép trong 1 phút (với API không chứng thực thì hiện nay được 10 request / phút) hoặc request được nhưng giá trị của `incomplete_results`(xem thêm ở [document](https://docs.github.com/en/free-pro-team@latest/rest/reference/search#timeouts-and-incomplete-results)) là `True` thì bạn sẽ cho chương trình sleep 1 giây rồi dậy thực hiện request lại, nếu vẫn chưa được thì lại sleep 1 giây ... Bạn lưu ý là, <font color=red>không được giả định lần request đầu tiên là chắc chắn thành công</font> (vì khi chấm bài mình sẽ phải chạy nhiều bài và có thể đến bài của bạn đã hết lượt request được phép)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Output trả về của hàm `collect_repositories`:\n",
    "- `repositories`: là list các thùng chứa lấy được (list gồm \"item\" của tất cả các trang)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20cb81a6aca154078aed4053c325d8ec",
     "grade": false,
     "grade_id": "cell-62a49f8fda9cd909",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def collect_repositories(start_date, end_date, keyword='data science', per_page=100):\n",
    "    repositories = []\n",
    "    # YOUR CODE HERE\n",
    "    kt = True\n",
    "    while(kt):\n",
    "        r = requests.get(f'https://api.github.com/search/repositories?q={keyword} created:{start_date}..{end_date}&per_page={per_page}')\n",
    "        if(r.ok == False):\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        kt = False\n",
    "    #r = requests.get('https://api.github.com/search/repositories?q=data+science+created%3A2017-01-01..2017-01-31&per_page=100&page=2')\n",
    "    json_pydata = json.loads(r.text) # Shortcut: json_pydata = r.json()\n",
    "    for i in range(len(json_pydata['items'])):\n",
    "        repositories.append(json_pydata['items'][i])\n",
    "    while(r.headers['Link'].find('rel=\"next\"') != -1):\n",
    "        links = r.headers['Link'].split(\",\")\n",
    "        for i in links:\n",
    "            if (i.find('rel=\"next\"') != -1):\n",
    "                link = re.findall(r'<(.+)>; rel=\"next\"',i)[0]\n",
    "        print(link)\n",
    "        kt = True\n",
    "        while(kt):\n",
    "            r = requests.get(link)\n",
    "            if(r.ok == False):\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            kt = False\n",
    "        json_pydata = json.loads(r.text) # Shortcut: json_pydata = r.json()\n",
    "        for i in range(len(json_pydata['items'])):\n",
    "            repositories.append(json_pydata['items'][i])\n",
    "    return repositories\n",
    "    raise NotImplementedError()\n",
    "collect_repositories('2017-01-01' , '2017-01-15', keyword='data science', per_page=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e6f450a5a2bafe89fda0fa4edc6d3b8",
     "grade": true,
     "grade_id": "cell-f9dd722733b1a0b8",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2017-01-15'\n",
    "keyword = 'data science'\n",
    "per_page = 100\n",
    "repositories = collect_repositories(start_date, end_date, keyword, per_page)\n",
    "print(len(repositories))\n",
    "\n",
    "url = f'https://api.github.com/search/repositories?q={keyword} created:{start_date}..{end_date}'\n",
    "finish = False\n",
    "while finish == False:\n",
    "    r = requests.get(url)\n",
    "    if r.ok == True:\n",
    "        json_pydata = r.json()\n",
    "        if json_pydata['incomplete_results'] == False: \n",
    "            total_count = json_pydata['total_count']\n",
    "            finish = True\n",
    "    else:\n",
    "        time.sleep(1)\n",
    "assert len(repositories) == total_count "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 2.2. Thu thập nhiều hơn 1000 thùng chứa (2.5đ)\n",
    "Để thu thập hết 1570 thùng chứa trong ví dụ ở trên, ta sẽ: \n",
    "- Chia khoảng thời gian các thùng chứa được tạo mà ta cần tìm kiếm ra các khoảng thời gian nhỏ hơn. Ví dụ chia 2017-01-01..2017-01-15 thành 2017-01-01..2017-01-07, 2017-01-08..2017-01-14, 2017-01-15..2017-01-15; ở đây, mỗi khoảng thời gian nhỏ gồm 7 ngày (kể cả 2 đầu), khoảng thời gian nhỏ sau cùng có thể sẽ không đủ 7 ngày (do bị lẻ). Trong Python, để làm việc với dữ liệu thời gian, bạn có thể dùng thư viện `datetime`; bạn có thể tự tìm hiểu về thư viện này ở: [document](https://docs.python.org/3.7/library/datetime.html), [Corey's video](https://www.youtube.com/watch?v=eirjjyP2qcQ), Google.\n",
    "- Tìm kiếm với khoảng thời gian nhỏ hơn này bằng hàm `collect_repositories` ở trên (với khoảng thời gian đủ nhỏ sẽ có $\\le1000$ thùng chứa).\n",
    "- Kết hợp kết quả từ các lần tìm kiếm với các khoảng thời gian nhỏ này lại.\n",
    "\n",
    "Bạn sẽ cài đặt các bước này ở hàm `collect_all_repositories` dưới đây. Hàm này có các input:\n",
    "- `start_date`, `end_date`, `keyword`, `per_page`: các input này giống như ở hàm `collect_repositories`.\n",
    "- `step`: là số nguyên, cho biết khoảng thời gian nhỏ gồm bao nhiêu ngày (tính cả 2 đầu). Trong ví dụ ở trên, `step=7`.\n",
    "\n",
    "Output trả về của hàm này:\n",
    "- `all_repositories`: là list tất cả các thùng chứa (\"item\") lấy được."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e58dcaf52d67ca4b5a41299b636282ab",
     "grade": false,
     "grade_id": "cell-186ad6493e39e40c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-230-ba672b8acbb9>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-230-ba672b8acbb9>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    a = real_end_date - real_start date\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def collect_all_repositories(start_date, end_date, step, keyword='data science', per_page=100):\n",
    "    all_repositories = []\n",
    "    # YOUR CODE HERE\n",
    "    real_start_date = dt.datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    real_end_date = dt.datetime.strptime(end_date, \"%Y-%m-%d\").date()\n",
    "    new_step = dt.timedelta(days = (step))\n",
    "    a = real_end_date - real_start date\n",
    "    print(a)g9t\n",
    "    #while True:\n",
    "        #if( real_end_date - temp_start date < step)\n",
    "    return all_repositories\n",
    "    raise NotImplementedError()\n",
    "collect_all_repositories('2017-01-01','2017-01-31', step = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e10538857f0a28d84ee3ae2e659cbcc5",
     "grade": true,
     "grade_id": "cell-eb93b1b4dd11e993",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2017-01-31'\n",
    "step = 10\n",
    "keyword = 'data science'\n",
    "per_page = 100\n",
    "all_repositories = collect_all_repositories(start_date, end_date, step, keyword, per_page)\n",
    "print(len(all_repositories))\n",
    "\n",
    "url = f'https://api.github.com/search/repositories?q={keyword} created:{start_date}..{end_date}'\n",
    "finish = False\n",
    "while finish == False:\n",
    "    r = requests.get(url)\n",
    "    if r.ok == True:\n",
    "        json_pydata = r.json()\n",
    "        if json_pydata['incomplete_results'] == False: \n",
    "            total_count = json_pydata['total_count']\n",
    "            finish = True\n",
    "    else:\n",
    "        time.sleep(1)\n",
    "assert len(all_repositories) == total_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
